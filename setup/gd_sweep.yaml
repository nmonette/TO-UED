command:
  - python3.11
  - "-m"
  - train_ued
  - "--log"
  - "--true_regret"
  - ${args_no_boolean_flags}
entity: flair
project: to-ued-hypers-sweep
method: random
name: gd-seed-sweep
metric:
  goal: maximize
  name: solve_rate/holdout_mean
parameters:
  num_agents:
    values: [32, 64, 128]
  num_epochs:
    distribution: int_uniform
    min: 2
    max: 8
  num_mini_batches:
    values: [1, 2, 4, 8]
  regret_frequency:
    distribution: int_uniform
    min: 5
    max: 50
  env_reset_method:
    value: "finite"
  wandb_project:
    value: "to-ued-seed-sweep"
  wandb_entity:
    value: flair
  method:
    value: "GD-TD"
  actor_lr:
    distribution: uniform
    min: 0.00005
    max: 0.001
  train_rollout_len:
    value: 251
  gamma:
    value: 0.995
  gae_lambda:
    value: 0.98
  meta_gamma:
    distribution: uniform
    min: 0.9
    max: 1.0
  meta_value_lr:
    distribution: uniform
    min: 0.001
    max: 0.01
  wandb_project:
    value: "bug-ablation-dr" 
  wandb_entity:
    value: "nathanmonette1"
  train_steps:
    value: 15000
  ogd_learning_rate:
    distribution: uniform
    min: 0.001
    max: 0.1
  ogd_trunc_size:
    distribution: uniform
    min: 1e-8
    max: 1e-5
  p_replay:
    distribution: uniform
    min: 0.5
    max: 0.8
  ppo_entropy_coeff:
    distribution: uniform
    min: 0.001
    max: 0.1
